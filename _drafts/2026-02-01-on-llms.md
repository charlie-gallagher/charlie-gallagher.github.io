# On LLMs
There's not much to contribute to the conversations around using LLMs, but maybe
there's some value in a case study.

```
Subject: Charlie (me)
Age: 29
Profession: Data analytics engineer
Background: Schooled in economics and econometrics. Informal education in
    low-level computing, operating systems, and data visualization.
Motivations: toolmaking, understanding problems, building something that works
```

I use Cursor, but I don't connect with it the way I see some people connect with
their LLMs. I work as a professional programmer, and I know that I'm expected to
increase my own output using Cursor. I'm neither excited nor depressed by it.

I like a definition I heard of LLMs as (in part) _pattern amplfication
machines_, and I do feel satisfied when Cursor takes care of a pesky refactor. I
chat to think through problems and get ideas, and I have written a _heap_ of
one-off scripts using Cursor. LLMs are killer "boilerplate-be-gone" tools, as
their reputation belies.

I feel the most useful to my organization when I understand problems deeply and
can talk about solutions on the fly, and so I avoid using LLMs in a way that
limits my understanding of the problems I'm dealing with. This hasn't meant
avoiding LLMs, but it does mean that when I'm working towards understanding, I
prefer slowing down to speeding up, and I'm skeptical rather than confident. It
also means speeding up those parts of my job that _don't_ require
thoughtfulness.

My title is "data analytics engineer." My company, IXIS Analytics, provides
several services to our clients including bespoke analyses and a centralized BI
platform. As a data analytics engineer, my job is to make sure that data is
available in a useful form to everyone who needs it -- from data engineers to
analysts to the BI platform. There is an unbound number of ways to solve each
organizational problem, so my role is to pick between them. There's not a lot of
technical wizardry involved. (I have to do that in my spare time.) Instead, it's
about nudging the organization in a direction that's not likely to fail,
choosing among alternatives, and -- most importantly -- deciding what to invest
in next. Should we invest in a new data warehouse or a new orchestrator tool? Is
it worth splitting this table up, considering backfills will be faster but using
the data will be more complex?

A lot of my job is thinking about the _timing_ of changes, not making the
changes themselves. And as with all products, data products have customers, and
you have to find ways to improve the product without making your customers worse
off. It's a fun space to work in, always challenging.

The other side of the job is knowing how to do tasks that we have not yet
automated or cannot automate -- reviewing merge requests, thinking of different
ways to integrate or separate datasets, replacing components in some data
pipeline somewhere, considering whether there's an opportunity to simplify
things, and all the mundane data tasks like executing backfills and tracing data
issues through our ingestion system.

To be honest, a lot of my job isn't LLM-friendly because there isn't a ton of
feedback. The ingestion and processing systems are a little informal and require
a decent amount of intuition still (which we're working on reducing). Steps like
"If there's no log message here, check this S3 location." It often ends up being
the case that the time I would spend as much time giving an LLM context on the
issue as I would doing the thing myself.

I'm looking forward to the day when our stack is more agent-friendly, but I also
hope that we skip that step and go right to automation.

I also like to work on computer projects in my free time, and it's here that I
leave Cursor mostly behind. Once I close my work laptop and open up my _fun_
laptop, I don't want industrial scale manpower. I like to slowly hack through
problems that bug me. If I'm learning to use Wireshark to understand a certain
networking protocol better, what good is it to have a team of agents at my
disposal?

There's a particular feeling I'm chasing when I program for fun. It's this sense
of understanding you get when you find the section of the manpage that explains
your use case and how it fits into the tool's worldview. Or when you stumble on
the name of something you've been hunting for. _Oh so_ readline _is the program
that controls line editing in my shell._ It's how the jigsaw computer pieces fit
together, with the stories of politicking and devotion and people.

I like that part of learning about computers, and LLMs don't do much for it.
(Though as a research tool, they're particularly excellent literature hunters.)

There are parts of LLMs that plain rub me the wrong way. This might not be an
insightful list, but it deserves inclusion nonetheless:

- Agents feel like an industrial tool. Great for industry, less great for fun.
  - Note: like anything, _someone_ builds these tools, and that sounds like it
    would be fun. But as a black box system, the charm wears off.
- They're expensive. My own wallet aside, there are class implications in the
  back of my mind, because there's no chance LLMs stay affordable long term, and
job placements will be won by those who can afford the tooling.
- They reduce the charm of accomplishing something. Where was my sweat, the
  result of my effort? (Counter-example: [Isometric NYC](https://cannoneyed.com/projects/isometric-nyc))
- The companies behind it. It's a space saturated with people hocking garbage,
  and it's hard to feel excited about it when it's so heavily polluted. To me,
it's not much different from blockchain technology, which was legimately
interesting besides the amount of sketchiness. (Counter-example: [Register
Spill](https://registerspill.thorstenball.com))
- There's something just fundamentally not fun about using tech that has the
  potential to upend people's careers. Am I going to use it to stay competitive?
Of course. But it's not a passion driver.

I'm not too worried about the future of software. The volume of available
software will increase, but there's always been a huge volume of software.
Network effects and dependable support play a much larger role in software
oligarchies than volume or specificity. Personalized software sounds like an
exercise in torture for anyone in a rush or who isn't that interested in the
product as an end in itself. Which is most people, you'd sort of have to think.

Ok case study over.

---

Charlie Gallagher, February 2026
